{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":61542,"databundleVersionId":6888007,"sourceType":"competition"},{"sourceId":6867914,"sourceType":"datasetVersion","datasetId":3946973},{"sourceId":6890527,"sourceType":"datasetVersion","datasetId":3942644},{"sourceId":137768005,"sourceType":"kernelVersion"},{"sourceId":5913,"sourceType":"modelInstanceVersion","modelInstanceId":4686}],"dockerImageVersionId":30626,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-25T12:59:36.758224Z","iopub.execute_input":"2024-01-25T12:59:36.758746Z","iopub.status.idle":"2024-01-25T12:59:36.787375Z","shell.execute_reply.started":"2024-01-25T12:59:36.758702Z","shell.execute_reply":"2024-01-25T12:59:36.786472Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"/kaggle/input/daigt-proper-train-dataset/train_drcat_03.csv\n/kaggle/input/daigt-proper-train-dataset/train_drcat_02.csv\n/kaggle/input/daigt-proper-train-dataset/train_drcat_04.csv\n/kaggle/input/daigt-proper-train-dataset/train_drcat_01.csv\n/kaggle/input/deberta_v3/keras/deberta_v3_base_en/1/config.json\n/kaggle/input/deberta_v3/keras/deberta_v3_base_en/1/tokenizer.json\n/kaggle/input/deberta_v3/keras/deberta_v3_base_en/1/metadata.json\n/kaggle/input/deberta_v3/keras/deberta_v3_base_en/1/model.weights.h5\n/kaggle/input/deberta_v3/keras/deberta_v3_base_en/1/assets/tokenizer/vocabulary.spm\n/kaggle/input/transformers-model-downloader-pytorch-tf2-0/__results__.html\n/kaggle/input/transformers-model-downloader-pytorch-tf2-0/__notebook__.ipynb\n/kaggle/input/transformers-model-downloader-pytorch-tf2-0/__output__.json\n/kaggle/input/transformers-model-downloader-pytorch-tf2-0/custom.css\n/kaggle/input/transformers-model-downloader-pytorch-tf2-0/microsoft/deberta-v3-base/spm.model\n/kaggle/input/transformers-model-downloader-pytorch-tf2-0/microsoft/deberta-v3-base/config.json\n/kaggle/input/transformers-model-downloader-pytorch-tf2-0/microsoft/deberta-v3-base/tokenizer.json\n/kaggle/input/transformers-model-downloader-pytorch-tf2-0/microsoft/deberta-v3-base/tokenizer_config.json\n/kaggle/input/transformers-model-downloader-pytorch-tf2-0/microsoft/deberta-v3-base/pytorch_model.bin\n/kaggle/input/transformers-model-downloader-pytorch-tf2-0/microsoft/deberta-v3-base/special_tokens_map.json\n/kaggle/input/transformers-model-downloader-pytorch-tf2-0/microsoft/deberta-v3-base/added_tokens.json\n/kaggle/input/argugpt/argugpt.csv\n/kaggle/input/argugpt/machine-dev.csv\n/kaggle/input/argugpt/machine-test.csv\n/kaggle/input/argugpt/machine-train.csv\n/kaggle/input/llm-detect-ai-generated-text/sample_submission.csv\n/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv\n/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\n/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Import Necessary Library","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\nfrom transformers import AutoModel\nfrom transformers import AutoTokenizer\nfrom tokenizers import Tokenizer, trainers, pre_tokenizers, models\nfrom transformers import DebertaTokenizer\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize.treebank import TreebankWordDetokenizer\nfrom collections import Counter\nfrom torchsummary import summary\n#import spacy\nimport re\nimport gc\n# ----------\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-01-25T12:59:52.198956Z","iopub.execute_input":"2024-01-25T12:59:52.199357Z","iopub.status.idle":"2024-01-25T12:59:52.213045Z","shell.execute_reply.started":"2024-01-25T12:59:52.199311Z","shell.execute_reply":"2024-01-25T12:59:52.211810Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"### Import Data\nThe notebook uses two datasets: **train_essays.csv** and **train_drcat_04.csv**. <br>\n**train_essays.csv** is provided by the competition host, while the label is highly imbalanced.<br> **train_drcat_04.csv** is the dataset provided by one of the participants of the competition.","metadata":{}},{"cell_type":"code","source":"train_essays = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\")\nexternal = pd.read_csv(\"/kaggle/input/daigt-proper-train-dataset/train_drcat_04.csv\")\nexternal","metadata":{"execution":{"iopub.status.busy":"2024-01-25T12:59:52.216103Z","iopub.execute_input":"2024-01-25T12:59:52.216466Z","iopub.status.idle":"2024-01-25T12:59:53.874234Z","shell.execute_reply.started":"2024-01-25T12:59:52.216435Z","shell.execute_reply":"2024-01-25T12:59:53.873050Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"                 essay_id                                               text  \\\n0            E897534557AF   In recent years, technology has had a profoun...   \n1            DFBA34FFE11D  Should students participate in an extracurricu...   \n2                af37ecf5  The electoral college is a symbol of mockery a...   \n3            5EC2696BAD78  This is why I think the principle should allow...   \n4         llama_70b_v1843  I strongly believe that meditation and mindful...   \n...                   ...                                                ...   \n44201        F7341069C4A4  \"Oh man I didn't make the soccer team!\", yelle...   \n44202        AFE6E553DAC2  I believe that using this technology could be ...   \n44203  falcon_180b_v1_600  The Face on Mars is a fascinating phenomenon t...   \n44204        A5F84C104693  Texting & Driving\\n\\nUsing your phone while dr...   \n44205        A148C659E98B  Dear Principal,\\n\\nI have been really good thi...   \n\n       label                source  \\\n0          1  mistral7binstruct_v2   \n1          0       persuade_corpus   \n2          0          train_essays   \n3          0       persuade_corpus   \n4          1          llama_70b_v1   \n...      ...                   ...   \n44201      0       persuade_corpus   \n44202      0       persuade_corpus   \n44203      1        falcon_180b_v1   \n44204      0       persuade_corpus   \n44205      0       persuade_corpus   \n\n                                                  prompt  fold  \n0      \\nTask: Write an essay discussing the positive...     1  \n1                                                    NaN     2  \n2                                                    NaN     5  \n3                                                    NaN     8  \n4      Some schools have implemented meditation and m...     0  \n...                                                  ...   ...  \n44201                                                NaN     7  \n44202                                                NaN     8  \n44203  You have read the article 'Unmasking the Face ...     3  \n44204                                                NaN     1  \n44205                                                NaN     4  \n\n[44206 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>essay_id</th>\n      <th>text</th>\n      <th>label</th>\n      <th>source</th>\n      <th>prompt</th>\n      <th>fold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>E897534557AF</td>\n      <td>In recent years, technology has had a profoun...</td>\n      <td>1</td>\n      <td>mistral7binstruct_v2</td>\n      <td>\\nTask: Write an essay discussing the positive...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>DFBA34FFE11D</td>\n      <td>Should students participate in an extracurricu...</td>\n      <td>0</td>\n      <td>persuade_corpus</td>\n      <td>NaN</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>af37ecf5</td>\n      <td>The electoral college is a symbol of mockery a...</td>\n      <td>0</td>\n      <td>train_essays</td>\n      <td>NaN</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5EC2696BAD78</td>\n      <td>This is why I think the principle should allow...</td>\n      <td>0</td>\n      <td>persuade_corpus</td>\n      <td>NaN</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>llama_70b_v1843</td>\n      <td>I strongly believe that meditation and mindful...</td>\n      <td>1</td>\n      <td>llama_70b_v1</td>\n      <td>Some schools have implemented meditation and m...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>44201</th>\n      <td>F7341069C4A4</td>\n      <td>\"Oh man I didn't make the soccer team!\", yelle...</td>\n      <td>0</td>\n      <td>persuade_corpus</td>\n      <td>NaN</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>44202</th>\n      <td>AFE6E553DAC2</td>\n      <td>I believe that using this technology could be ...</td>\n      <td>0</td>\n      <td>persuade_corpus</td>\n      <td>NaN</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>44203</th>\n      <td>falcon_180b_v1_600</td>\n      <td>The Face on Mars is a fascinating phenomenon t...</td>\n      <td>1</td>\n      <td>falcon_180b_v1</td>\n      <td>You have read the article 'Unmasking the Face ...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>44204</th>\n      <td>A5F84C104693</td>\n      <td>Texting &amp; Driving\\n\\nUsing your phone while dr...</td>\n      <td>0</td>\n      <td>persuade_corpus</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>44205</th>\n      <td>A148C659E98B</td>\n      <td>Dear Principal,\\n\\nI have been really good thi...</td>\n      <td>0</td>\n      <td>persuade_corpus</td>\n      <td>NaN</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>44206 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.concat([\n    external[external.source==\"persuade_corpus\"].sample(10000),\n    external[external.source!='persuade_corpus']\n])","metadata":{"execution":{"iopub.status.busy":"2024-01-25T12:59:53.875574Z","iopub.execute_input":"2024-01-25T12:59:53.875911Z","iopub.status.idle":"2024-01-25T12:59:53.919852Z","shell.execute_reply.started":"2024-01-25T12:59:53.875883Z","shell.execute_reply":"2024-01-25T12:59:53.918584Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"df = df.reset_index()","metadata":{"execution":{"iopub.status.busy":"2024-01-25T12:59:53.921377Z","iopub.execute_input":"2024-01-25T12:59:53.921747Z","iopub.status.idle":"2024-01-25T12:59:53.938471Z","shell.execute_reply.started":"2024-01-25T12:59:53.921718Z","shell.execute_reply":"2024-01-25T12:59:53.937085Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"df['stratify'] = df.label.astype(str)+df.source.astype(str)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-25T12:59:53.940482Z","iopub.execute_input":"2024-01-25T12:59:53.940870Z","iopub.status.idle":"2024-01-25T12:59:53.976808Z","shell.execute_reply.started":"2024-01-25T12:59:53.940839Z","shell.execute_reply":"2024-01-25T12:59:53.974995Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import transformers \nprint('transformers version:', transformers.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T12:59:53.978962Z","iopub.execute_input":"2024-01-25T12:59:53.979427Z","iopub.status.idle":"2024-01-25T12:59:53.985796Z","shell.execute_reply.started":"2024-01-25T12:59:53.979388Z","shell.execute_reply":"2024-01-25T12:59:53.984288Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"transformers version: 4.36.0\n","output_type":"stream"}]},{"cell_type":"code","source":"config = {\n    'model': '/kaggle/input/transformers-model-downloader-pytorch-tf2-0/microsoft/deberta-v3-base',\n    'dropout': 0.2,\n    'max_length': 512,\n    'batch_size':5,\n    'epochs': 5,\n    'lr': 1e-5,\n    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n    'scheduler': 'CosineAnnealingWarmRestarts'\n}","metadata":{"execution":{"iopub.status.busy":"2024-01-25T12:59:53.987300Z","iopub.execute_input":"2024-01-25T12:59:53.987834Z","iopub.status.idle":"2024-01-25T12:59:53.998334Z","shell.execute_reply.started":"2024-01-25T12:59:53.987794Z","shell.execute_reply":"2024-01-25T12:59:53.996788Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"#tokenizer = Tokenizer(models.BPE())\n#tokenizer.pre_tokenizer= pre_tokenizers.Whitespace()\n#trainer = trainers.BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"]) \n#tokenizer.train_from_iterator(df['text'], trainer=trainer)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T12:59:54.004544Z","iopub.execute_input":"2024-01-25T12:59:54.005091Z","iopub.status.idle":"2024-01-25T12:59:54.011765Z","shell.execute_reply.started":"2024-01-25T12:59:54.005060Z","shell.execute_reply":"2024-01-25T12:59:54.010357Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train_df,val_df = train_test_split(df,test_size=0.2,random_state = 101,stratify=df['stratify'])\ntrain_df, val_df = train_df.reset_index(), val_df.reset_index()\nprint('dataframe shapes:',train_df.shape, val_df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T12:59:54.013564Z","iopub.execute_input":"2024-01-25T12:59:54.014076Z","iopub.status.idle":"2024-01-25T12:59:54.111114Z","shell.execute_reply.started":"2024-01-25T12:59:54.014036Z","shell.execute_reply":"2024-01-25T12:59:54.109854Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"dataframe shapes: (22568, 9) (5642, 9)\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(config['model'])\ntokenizer.train_new_from_iterator(train_essays['text'], 52000)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T12:59:54.113326Z","iopub.execute_input":"2024-01-25T12:59:54.114190Z","iopub.status.idle":"2024-01-25T12:59:56.923455Z","shell.execute_reply.started":"2024-01-25T12:59:54.114145Z","shell.execute_reply":"2024-01-25T12:59:56.922513Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"\n\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"DebertaV2TokenizerFast(name_or_path='/kaggle/input/transformers-model-downloader-pytorch-tf2-0/microsoft/deberta-v3-base', vocab_size=16815, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n}"},"metadata":{}}]},{"cell_type":"code","source":"test_essays = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-01-25T12:59:56.924843Z","iopub.execute_input":"2024-01-25T12:59:56.925848Z","iopub.status.idle":"2024-01-25T12:59:56.934217Z","shell.execute_reply.started":"2024-01-25T12:59:56.925814Z","shell.execute_reply":"2024-01-25T12:59:56.932976Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-01-25T12:59:56.936707Z","iopub.execute_input":"2024-01-25T12:59:56.937832Z","iopub.status.idle":"2024-01-25T12:59:56.960547Z","shell.execute_reply.started":"2024-01-25T12:59:56.937777Z","shell.execute_reply":"2024-01-25T12:59:56.959682Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"       index               essay_id  \\\n0      30953           A040DFB142C9   \n1      22108           0C9DF15EB6EA   \n2      34621           9BAE97BE9789   \n3       8681           EB94208AC8AF   \n4      21589           3E2D5548BCD3   \n...      ...                    ...   \n28205  44190     falcon_180b_v1_261   \n28206  44195           BDF13939FA26   \n28207  44197  1ed36fd42635_04112023   \n28208  44199               d8f15f7d   \n28209  44203     falcon_180b_v1_600   \n\n                                                    text  label  \\\n0      Dear,Principal\\n\\nI am writing this letter to ...      0   \n1      As a kid in school I do not think distance lea...      0   \n2      People for many years have always been fasinat...      0   \n3      Dear Principal,\\n\\nI'm writing you a letter in...      0   \n4      Limiting usage of cars is actually a very good...      0   \n...                                                  ...    ...   \n28205  I think it's a good idea for schools to have o...      1   \n28206   Students often debate whether inactivity or s...      1   \n28207  The Seagoing Cowboys program is an amazing opp...      1   \n28208  Advantages of Limiting Car Usage\\n\\nLimiting c...      1   \n28209  The Face on Mars is a fascinating phenomenon t...      1   \n\n                     source  \\\n0           persuade_corpus   \n1           persuade_corpus   \n2           persuade_corpus   \n3           persuade_corpus   \n4           persuade_corpus   \n...                     ...   \n28205        falcon_180b_v1   \n28206  mistral7binstruct_v2   \n28207     darragh_claude_v6   \n28208             radek_500   \n28209        falcon_180b_v1   \n\n                                                  prompt  fold  \\\n0                                                    NaN     3   \n1                                                    NaN     8   \n2                                                    NaN     9   \n3                                                    NaN     5   \n4                                                    NaN     3   \n...                                                  ...   ...   \n28205  Some schools have implemented policies that al...     0   \n28206  \\nTask: Research the benefits of staying occup...     3   \n28207                                                NaN     5   \n28208                                                NaN     0   \n28209  You have read the article 'Unmasking the Face ...     3   \n\n                    stratify  \n0           0persuade_corpus  \n1           0persuade_corpus  \n2           0persuade_corpus  \n3           0persuade_corpus  \n4           0persuade_corpus  \n...                      ...  \n28205        1falcon_180b_v1  \n28206  1mistral7binstruct_v2  \n28207     1darragh_claude_v6  \n28208             1radek_500  \n28209        1falcon_180b_v1  \n\n[28210 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>essay_id</th>\n      <th>text</th>\n      <th>label</th>\n      <th>source</th>\n      <th>prompt</th>\n      <th>fold</th>\n      <th>stratify</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30953</td>\n      <td>A040DFB142C9</td>\n      <td>Dear,Principal\\n\\nI am writing this letter to ...</td>\n      <td>0</td>\n      <td>persuade_corpus</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>0persuade_corpus</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22108</td>\n      <td>0C9DF15EB6EA</td>\n      <td>As a kid in school I do not think distance lea...</td>\n      <td>0</td>\n      <td>persuade_corpus</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>0persuade_corpus</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>34621</td>\n      <td>9BAE97BE9789</td>\n      <td>People for many years have always been fasinat...</td>\n      <td>0</td>\n      <td>persuade_corpus</td>\n      <td>NaN</td>\n      <td>9</td>\n      <td>0persuade_corpus</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8681</td>\n      <td>EB94208AC8AF</td>\n      <td>Dear Principal,\\n\\nI'm writing you a letter in...</td>\n      <td>0</td>\n      <td>persuade_corpus</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>0persuade_corpus</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>21589</td>\n      <td>3E2D5548BCD3</td>\n      <td>Limiting usage of cars is actually a very good...</td>\n      <td>0</td>\n      <td>persuade_corpus</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>0persuade_corpus</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>28205</th>\n      <td>44190</td>\n      <td>falcon_180b_v1_261</td>\n      <td>I think it's a good idea for schools to have o...</td>\n      <td>1</td>\n      <td>falcon_180b_v1</td>\n      <td>Some schools have implemented policies that al...</td>\n      <td>0</td>\n      <td>1falcon_180b_v1</td>\n    </tr>\n    <tr>\n      <th>28206</th>\n      <td>44195</td>\n      <td>BDF13939FA26</td>\n      <td>Students often debate whether inactivity or s...</td>\n      <td>1</td>\n      <td>mistral7binstruct_v2</td>\n      <td>\\nTask: Research the benefits of staying occup...</td>\n      <td>3</td>\n      <td>1mistral7binstruct_v2</td>\n    </tr>\n    <tr>\n      <th>28207</th>\n      <td>44197</td>\n      <td>1ed36fd42635_04112023</td>\n      <td>The Seagoing Cowboys program is an amazing opp...</td>\n      <td>1</td>\n      <td>darragh_claude_v6</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>1darragh_claude_v6</td>\n    </tr>\n    <tr>\n      <th>28208</th>\n      <td>44199</td>\n      <td>d8f15f7d</td>\n      <td>Advantages of Limiting Car Usage\\n\\nLimiting c...</td>\n      <td>1</td>\n      <td>radek_500</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1radek_500</td>\n    </tr>\n    <tr>\n      <th>28209</th>\n      <td>44203</td>\n      <td>falcon_180b_v1_600</td>\n      <td>The Face on Mars is a fascinating phenomenon t...</td>\n      <td>1</td>\n      <td>falcon_180b_v1</td>\n      <td>You have read the article 'Unmasking the Face ...</td>\n      <td>3</td>\n      <td>1falcon_180b_v1</td>\n    </tr>\n  </tbody>\n</table>\n<p>28210 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Building Training Dataset and Loader","metadata":{}},{"cell_type":"code","source":"class EssayDataset:\n    def __init__(self, df, config,tokenizer, is_test = False):   \n        self.df = df\n        self.tokenizer = tokenizer\n        self.is_test = is_test\n        self.config = config\n    \n    def token_start(self, idx):\n        sample_text = self.df.loc[idx,'text']\n        \n        tokenized = tokenizer.encode_plus(sample_text,\n                                          None,\n                                          add_special_tokens=True,\n                                          max_length= self.config['max_length'],\n                                          truncation=True,\n                                          padding=\"max_length\"\n                                         )\n        \n        inputs = {\n           \"input_ids\": torch.tensor(tokenized['input_ids'],dtype=torch.long),\n            \"token_type_ids\": torch.tensor(tokenized['token_type_ids'],dtype=torch.long),\n            \"attention_mask\": torch.tensor(tokenized['attention_mask'],dtype = torch.long)\n        } \n        \n        return inputs\n        \n    \n    def __getitem__(self,idx):\n        \n        input_text = self.token_start(idx)\n        \n        if self.is_test:\n            return input_text\n        \n        else:\n            labels = self.df.loc[idx,'label']\n            targets = {'labels' : torch.tensor(labels,dtype = torch.float32)}\n            \n            return input_text,targets\n        \n    def __len__(self):\n        return len(self.df)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T12:59:56.961760Z","iopub.execute_input":"2024-01-25T12:59:56.963225Z","iopub.status.idle":"2024-01-25T12:59:56.975997Z","shell.execute_reply.started":"2024-01-25T12:59:56.963189Z","shell.execute_reply":"2024-01-25T12:59:56.974837Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"train_ds = EssayDataset(train_df,config,tokenizer = tokenizer)\nval_ds = EssayDataset(val_df,config,tokenizer = tokenizer)\ntest_ds = EssayDataset(test_essays,config,tokenizer = tokenizer,is_test = True)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T12:59:56.977325Z","iopub.execute_input":"2024-01-25T12:59:56.977680Z","iopub.status.idle":"2024-01-25T12:59:56.989727Z","shell.execute_reply.started":"2024-01-25T12:59:56.977649Z","shell.execute_reply":"2024-01-25T12:59:56.988804Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(train_ds,\n                          batch_size= config['batch_size'])\nval_loader = torch.utils.data.DataLoader(val_ds,\n                          batch_size= config['batch_size'])\ntest_loader = torch.utils.data.DataLoader(test_ds,\n                          batch_size= config['batch_size'])","metadata":{"execution":{"iopub.status.busy":"2024-01-25T12:59:56.991214Z","iopub.execute_input":"2024-01-25T12:59:56.991832Z","iopub.status.idle":"2024-01-25T12:59:57.209717Z","shell.execute_reply.started":"2024-01-25T12:59:56.991802Z","shell.execute_reply":"2024-01-25T12:59:57.208302Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"### Model\nFine tuning the deberta-v3-base model with new-added layers","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nclass MeanPooling(nn.Module):\n    def __init__(self):\n        super(MeanPooling,self).__init__()\n        \n    \n    def forward(self,last_hidden_state, attention_mask):\n        new_weight = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        final = torch.sum(new_weight*last_hidden_state,1)\n        total_weight = new_weight.sum(1)\n        total_weight = torch.clamp(total_weight, min = 1e-9)\n        mean_embedding = final/total_weight\n        \n        return mean_embedding","metadata":{"execution":{"iopub.status.busy":"2024-01-25T12:59:57.213046Z","iopub.execute_input":"2024-01-25T12:59:57.213996Z","iopub.status.idle":"2024-01-25T12:59:57.226035Z","shell.execute_reply.started":"2024-01-25T12:59:57.213948Z","shell.execute_reply":"2024-01-25T12:59:57.224768Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nclass mymodel(nn.Module):\n    \n    def __init__(self,config):\n        super(mymodel,self).__init__()\n        \n        self.model_name = config['model']\n        self.deberta = AutoModel.from_pretrained(self.model_name)\n        self.deberta.resize_token_embeddings(len(tokenizer))\n        self.dropout = nn.Dropout(config['dropout'])\n        self.fn0 = nn.Linear(self.deberta.config.hidden_size,256)\n        self.fn2 = nn.Linear(256,1)\n        self.pooling = MeanPooling()\n    \n    def forward(self, input):\n        output = self.deberta(**input,return_dict = True)\n        output = self.pooling(output['last_hidden_state'],input['attention_mask'])\n        output = self.dropout(output)\n        output = self.fn0(output)\n        output = self.dropout(output)\n        output = self.fn2(output)\n        output = torch.sigmoid(output)\n        return output\n        ","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:08:31.133348Z","iopub.execute_input":"2024-01-25T13:08:31.134084Z","iopub.status.idle":"2024-01-25T13:08:31.149413Z","shell.execute_reply.started":"2024-01-25T13:08:31.134033Z","shell.execute_reply":"2024-01-25T13:08:31.147831Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"class Trainer:\n    \n    def __init__(self,model,loaders,config):\n        self.model = model\n        self.train_loader,self.val_loader = loaders\n        self.config = config\n        self.input_keys = ['input_ids','token_type_ids','attention_mask']\n        self.optim = self.__get__optim()\n        self.scheduler_options = {\n            'CosineAnnealingWarmRestarts': torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(self.optim, T_0=5,eta_min=1e-7),\n            'ReduceLROnPlateau': torch.optim.lr_scheduler.ReduceLROnPlateau(self.optim, 'min', min_lr=1e-7),\n            'StepLR': torch.optim.lr_scheduler.StepLR(self.optim,step_size=2)\n        }\n        \n        self.scheduler = self.scheduler_options[self.config['scheduler']]\n        \n        self.train_losses = []\n        self.val_losses = []\n        \n    def __get__optim(self):\n        no_decay = ['bias', 'LayerNorm.weight']\n        optimizer_grouped_parameters = [\n            {'params': [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n            {'params': [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n        ]\n        optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=self.config['lr'])\n        return optimizer\n    \n    \n    def loss_fn(self,outputs,targets):\n        criterion = nn.BCELoss()\n        loss = criterion(outputs, targets)\n        \n        return loss\n    \n    \n    \n    def train_one_epoch(self,epoch):\n        \n        running_loss = 0\n        \n        progress = tqdm(self.train_loader,total=len(self.train_loader))\n        \n        for i,(inputs,targets) in enumerate(progress):\n            \n            self.optim.zero_grad()\n            inputs = {k:inputs[k].to(device=config['device']) for k in inputs.keys()}\n            targets = targets['labels'].to(device=config['device'])\n            \n            outputs= self.model(inputs)\n            targets = targets.view(-1, 1)\n            loss = self.loss_fn(outputs,targets)\n            \n            running_loss += loss.item()\n            \n            loss.backward()\n            self.optim.step()\n            self.scheduler.step()\n            \n            del inputs,targets\n        \n        train_loss = running_loss/len(self.train_loader)\n        self.train_losses.append(train_loss)\n        \n        \n    \n    @torch.no_grad()\n    def valid_one_epoch(self,epoch):\n        \n        running_loss = 0\n        progress = tqdm(self.val_loader,total=len(self.val_loader))\n        \n        for (input, targets) in progress:\n            \n            input = {k: input[k].to(device = config['device']) for k in input.keys()}\n            targets = targets['labels'].to(device = config['device'])\n            \n            outputs = self.model(input)\n            targets = targets.view(-1, 1)\n            loss = self.loss_fn(outputs,targets)\n            running_loss += loss.item()\n        \n        val_loss = running_loss/len(self.val_loader)\n        self.val_losses.append(val_loss)\n        \n        \n    def test(self,test_loader):\n        preds = []\n        for (inputs) in test_loader:\n            inputs = {k:inputs[k].to(device=config['device']) for k in inputs.keys()}\n            \n            outputs = self.model(inputs)\n            preds.append(outputs.detach().cpu())\n            \n        preds = torch.concat(preds)\n        return preds\n    \n    \n    \n    def fit(self):\n        fit_progress = tqdm(\n            range(1, self.config['epochs']+1),\n            leave = True,\n            desc=\"Training...\"\n        )\n        \n        for epoch in fit_progress:\n            \n            self.model.train()\n            fit_progress.set_description(f\"EPOCH {epoch} / {self.config['epochs']} | training...\")\n            self.train_one_epoch(epoch)\n            self.clear()\n            \n            self.model.eval()\n            fit_progress.set_description(f\"EPOCH {epoch} / {self.config['epochs']} | validating...\")\n            self.valid_one_epoch(epoch)\n            self.clear()\n\n            print(f\"{'-'*30} EPOCH {epoch} / {self.config['epochs']} {'-'*30}\")\n            print(f\"train loss: {self.train_losses[-1]}\")\n            print(f\"valid loss: {self.val_losses[-1]}\\n\\n\")\n            \n    def clear(self):\n        gc.collect()\n        torch.cuda.empty_cache()\n        ","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:08:34.071836Z","iopub.execute_input":"2024-01-25T13:08:34.072263Z","iopub.status.idle":"2024-01-25T13:08:34.103049Z","shell.execute_reply.started":"2024-01-25T13:08:34.072230Z","shell.execute_reply":"2024-01-25T13:08:34.102027Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"model = mymodel(config).to(device=config['device'])","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:08:41.252309Z","iopub.execute_input":"2024-01-25T13:08:41.252829Z","iopub.status.idle":"2024-01-25T13:08:43.700025Z","shell.execute_reply.started":"2024-01-25T13:08:41.252791Z","shell.execute_reply":"2024-01-25T13:08:43.698554Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(model, (train_loader,val_loader),config)\n\ntrainer.fit()","metadata":{"execution":{"iopub.status.busy":"2024-01-11T11:55:25.44163Z","iopub.execute_input":"2024-01-11T11:55:25.44191Z","iopub.status.idle":"2024-01-11T11:55:40.454887Z","shell.execute_reply.started":"2024-01-11T11:55:25.441887Z","shell.execute_reply":"2024-01-11T11:55:40.453426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.model.save_pretrained(\"trained-model\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_essays[\"generated\"]= trainer.test(test_loader).numpy()\n#test_essays = test_essays[[\"id\",\"generated\"]]\n#test_essays.to_csv(\"submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T11:55:40.456274Z","iopub.status.idle":"2024-01-11T11:55:40.456779Z","shell.execute_reply.started":"2024-01-11T11:55:40.456532Z","shell.execute_reply":"2024-01-11T11:55:40.456555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"losses_df = pd.DataFrame({'epoch':list(range(1,config['epochs']+1)),\n                         'train_loss':trainer.train_losses,\n                         'val_loss':trainer.val_losses})","metadata":{"execution":{"iopub.status.busy":"2024-01-11T11:55:40.457937Z","iopub.status.idle":"2024-01-11T11:55:40.458437Z","shell.execute_reply.started":"2024-01-11T11:55:40.458166Z","shell.execute_reply":"2024-01-11T11:55:40.458188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(trainer.train_losses, color='red')\nplt.plot(trainer.val_losses, color='orange')\nplt.title('BCE Loss')\nplt.legend(['Train', 'Validation'], loc='upper right')","metadata":{"execution":{"iopub.status.busy":"2024-01-11T11:55:40.460023Z","iopub.status.idle":"2024-01-11T11:55:40.460482Z","shell.execute_reply.started":"2024-01-11T11:55:40.46023Z","shell.execute_reply":"2024-01-11T11:55:40.460251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model is later used to participate the Kaggle Competition:LLM - Detect AI Generated Text.\nThe Auc of the model is 0.75","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}